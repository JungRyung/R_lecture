group_by(manufacturer)%>%
summarise(mean_cty=mean(cty),
mean_hwy=mean(hwy))%>%
arrange(desc(mean_cty))%>%
head(5))
df
ggplot(data=df,aes(x=manufacture,y=mean_cty)) + geom_col()
ggplot(data=df,aes(x=manufacture,y=mean_cty)) + geom_col()
ggplot(data=df,aes(x=manufacturer,y=mean_cty)) + geom_col()
ggplot(data=df,aes(x=reorder(desc(manufacturer)),y=mean_cty)) + geom_col()
ggplot(data=df,aes(x=reorder(manufacturer.mean_cty),y=mean_cty)) + geom_col()
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) + geom_col()
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5))
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip()
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() +
xlim(3,6) + ylim(10,30)
kk=ggplot(data = mpg, aes(x = cty, y = hwy)) +
geom_point()
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
# 08-2
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
df=as.data.frame(mpg %>%
filter(class=="suv")%>%
group_by(manufacturer)%>%
summarise(mean_cty=mean(cty),
mean_hwy=mean(hwy))%>%
arrange(desc(mean_cty))%>%
head(5))
df
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
midwest <- as.data.frame(ggplot2::midwest)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
ggplot(data = economics, aes(x = date, y = unemploy)) +
geom_line()
install.packages(ggthemes)
install.packages(ggplot2)
ggplot(data = economics, aes(x = date, y = unemploy)) +
geom_line()
# 08-4
## Q1. psavert의 시간에 따른 변화
ggplot(data = economics, aes(x = date, y = psavert)) +
geom_line()
## 08-5. 상자 그림 - 집단 간 분포 차이 표현하기
ggplot(data = mpg, aes(x = drv, y = hwy)) +
geom_boxplot()
install.packages("extrafont")
library(extrafont)
font_import()
ggplot(tt)
ggplot(data=mpg, aes(x=drv, y=hwy)) + geom_boxplot(
)
ggplot(data=economics, aes(x=date, y=psavert)) +
geom_line()
ggplot(data=economics, aes(x=date, y=psavert)) +
geom_line()
ggplot(data=mpg, aes(x=drv, y=hwy)) + geom_boxplot()
ggplot(data=mpg, aes(x=drv, y=hwy)) + geom_boxplot()
# 08-5
## Q1
class_mpg <- mpg %>%
filter(class %in% c("compact", "subcompact", "suv"))
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
# 08-5
## Q1
class_mpg <- mpg %>%
filter(class %in% c("compact", "subcompact", "suv"))
ggplot(data = class_mpg, aes(x = class, y = cty)) +
geom_boxplot()
setwd("./Rdata")  # <-- 작업 디렉토리는 임의로 지정하세요
# 08-2
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
theme_set(theme_gray(base_family='NanumGothic'))
# 08-2
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
df=as.data.frame(mpg %>%
filter(class=="suv")%>%
group_by(manufacturer)%>%
summarise(mean_cty=mean(cty),
mean_hwy=mean(hwy))%>%
arrange(desc(mean_cty))%>%
head(5))
# 08-2
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-2
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
install.packages(ggplot2)
library(ggplot2)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
df=as.data.frame(mpg %>%
filter(class=="suv")%>%
group_by(manufacturer)%>%
summarise(mean_cty=mean(cty),
mean_hwy=mean(hwy))%>%
arrange(desc(mean_cty))%>%
head(5))
# 08-2
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
library(ggplot2)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
df=as.data.frame(mpg %>%
filter(class=="suv")%>%
group_by(manufacturer)%>%
summarise(mean_cty=mean(cty),
mean_hwy=mean(hwy))%>%
arrange(desc(mean_cty))%>%
head(5))
# 08-2
par(family='Unbatang')
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
library(ggplot2)
## Q1. x축은 cty, y축은 hwy로 된 산점도
ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point()
## Q2. x축은 poptotal, y축은 popasian으로 된 산점도
ggplot(data = midwest, aes(x = poptotal, y = popasian)) + geom_point() +
xlim(0,500000) +
ylim(0,10000)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
df=as.data.frame(mpg %>%
filter(class=="suv")%>%
group_by(manufacturer)%>%
summarise(mean_cty=mean(cty),
mean_hwy=mean(hwy))%>%
arrange(desc(mean_cty))%>%
head(5))
df
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
# 08-3
## Q1.
kk=table(mpg$class)
tt=barplot(kk,col=rainbow(8),ylim=c(0,70))
text(tt,kk,paste0(kk,"대"),pos=3,col=2,cex=2)
df=as.data.frame(mpg %>%
filter(class=="suv")%>%
group_by(manufacturer)%>%
summarise(mean_cty=mean(cty),
mean_hwy=mean(hwy))%>%
arrange(desc(mean_cty))%>%
head(5))
df
ggplot(data=df,aes(x=reorder(manufacturer,mean_cty),y=mean_cty)) +
geom_col(fill=rainbow(5)) +
coord_flip() +
xlab("차종") +
ylab("평균도시연비")
# 08-2
mpg <- as.data.frame(ggplot2::mpg)
midwest <- as.data.frame(ggplot2::midwest)
#setwd("D:/development/R_lecture/Rdata")
setwd("/Users/ryung/Desktop/Development/R_lecture/Rdata")
data=read.csv("programming.csv")
head(data)
model=glm(Success~Experience,data=data,family = binomial(logit))
summary(model)
cbind(data$Experience, model$fitted.values)
plot(Success~Experience, data=data)
points(model$fitted.values~data$Experience,col=2)
# confusion matrix
table(data$Success,model$fitted.values>0.5)
c('민감도'=8/11, '특이도'=11/14) #민감도=true를 true로 답한 비율, 특이도=false를 false로 답한 비율
# 쿠폰의 할인율과 재구매의 상관관계 및 예측
data = read.csv("coupon.csv")
head(data)
model2 = glm(cbind(N_redeemed, N-N_redeemed)~Price_reduc,
data=data,family = binomial(logit))
summary(model2)
# Multiple Logistic Regression
# ex) Disease Outbreak
data = read.csv("disease.csv")
# full model
model3 = glm(disease~. , data=data, family = binomial(logit))
summary(model3)
# reduced model
model4 = glm(disease~age+sector,data=data,family=binomial(logit))
summary(model4)
anova(model3,model4,test='Chisq') # 독립성 검증
table(data$disease)
31/98
kk=table(data$disease,model4$fitted.values>0.3163265)
kk
sum(ss)
reduce_M=c('민감도'=23/31, '특이도'=47/(47+20))
kk1=table(data$disease,model3$fitted.values>0.3163265)
kk1
fullmode_M=c('민감도'=23/31, '특이도'=49/(49+18))
reduce_M
fullmode_M
err_m1=28/sum(kk)
err_m2=26/sum(kk1)
err_m1
err_m2
install.packages("Deducer")
rocplot(model3) # 아래면적이 더 넓을수록 좋은 모델
rocplot(model4)
rocplot(model3) # 아래면적이 더 넓을수록 좋은 모델
rocplot(model4)
library(Deducer)
install.packages("Deducer")
Yes
install.packages("Deducer")
library(Deducer)
library(ggpolt2)
install.packages(ggplot2)
install.packages(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
library(Deducer)
JGR()
library(Deducer)
rocplot(model3) # 아래면적이 더 넓을수록 좋은 모델
rocplot(model4)
JGR()
setwd("/Users/ryung/Desktop/Development/R_lecture/Rdata")
data = read.csv("flushot.csv")
head(data)
# 1. 주어진 세 개의 설명변수로 예방접종 확률을 예측하는 모형을 추정하여
#     추정된 로지스틱 회귀식을 써라.
log_model = glm(flushot~., data=data, family=binomial(logit))
summary(log_model)
# 2. EXP를 해석하라.
exp(0.07279)
exp(-0.09899)
exp(0.43397)
# 4. 유의하지 않은 설명변수가 있는지 Deviance goodness-of-fit test를
#   통해 판단하여 최종모형을 추정하라.
log_model2=glm(flushot~age+aware, data=data, family = binomial())
summary(log_model2)
table(data$flushot)
24/(134+24)
tt=table(data$flushot, log_model2$fitted.values>0.1518987)
c('민감도'=19/(5+19), '특이도'=95/(95+40), '에러율'=45/sum(tt))
rocplot(log_model2)
# 7. cutoff을 0.1, 0.15, 0.2로 두었을 때의 총 error rate와 민감도, 특이도를 계산하라.
tab_01=table(data$flushot, log_model2$fitted.values>0.1)
tab_015=table(data$flushot, log_model2$fitted.values>0.15)
tab_02=table(data$flushot, log_model2$fitted.values>0.2)
tab_01
tab_015
tab_02
res01=c('민감도'=tab_01[2,2]/sum(tab_01[2,]),
'특이도'=tab_01[1,1]/sum(tab_01[1,]),
'에러율'=(tab_01[1,2]+tab_01[2,1])/sum(tab_01))
res015=c('민감도'=tab_015[2,2]/sum(tab_015[2,]),
'특이도'=tab_015[1,1]/sum(tab_015[1,]),
'에러율'=(tab_015[1,2]+tab_015[2,1])/sum(tab_015))
res02=c('민감도'=tab_02[2,2]/sum(tab_02[2,]),
'특이도'=tab_02[1,1]/sum(tab_02[1,]),
'에러율'=(tab_02[1,2]+tab_02[2,1])/sum(tab_02))
res01
res015
res02 # cutoff이 0.2일 때 에러율이 가장 낮다
summary(log_model)
# 2. EXP를 해석하라.
exp(0.07279)
exp(-0.09899)
exp(0.43397)
anova(model3,model4,test='Chisq') # 독립성 검증
kk
sum(ss)
sum(kk)
jang=function(){
k=seq(0.01,0.5,0.1)
n=lengh(k)
err_min=vector(length = n)
sens=vector(length = n)
spec=vector(length = n)
for(i in 1:n){
tab=table(data$flushot, log_model2$fitted.values.values>k[i])
res=c('민감도'=tab[2,2]/sum(tab[2,]),
'특이도'=tab[1,1]/sum(tab[1,]),
'에러율'=(tab[1,2]+tab[2,1])/sum(tab))
sens[i]=tab[2,2]/sum(tab[2,])
spec[i]=tab[1,1]/sum(tab[1,])
err_min[i]=(tab[1,2]+tab[2,1])/sum(tab)
print(res)
}
index=which(err_min<=min(err_min))
print(paste("해당하는 민감도=",sens[min(index)],"이다."))
print(paste("해당하는 특이도=",spec[min(index)],"이다."))
print(paste("해당하는 에러율=",err_min[min(index)],"이다."))
print(paste("해당하는 cutoff=",k[min(index)],"이다."))
plot(1-spec,sens,col=2)
}
jang
crime = read.csv("http://datasets.flowingdata.com/crimeRatesByState-formatted.csv")
head(crime)
rownames(crime)
rownames(crime) = crime[,1]
rownames(crme)
rownames(crime)
rownames(crime)
rownames(crime) = crime[,1]
rownames(crime)
stars(crime[,2:8])
stars(crime[,2:8],flip.labels = FALSE)
stars(crime[,2:8],flip.labels = FALSE, draw.segments = TRUE)
stars(crime[,2:8],flip.labels = FALSE, draw.segments = TRUE,key.loc=c(15,1.5))
install.packages(aplpack)
install.packages("aplpack")
library(aplpack)
faces(crime[,2:8])
library(aplpack)
install.packages("XQuartz")
install.packages("aplpack")
library(aplpack)
faces(crime[,2:8])
library(aplpack)
faces(crime[,2:8])
plot(1-spec,sens,col=2)
plot(1~spec,sens,col=2)
print(paste("해당하는 민감도=",sens[min(index)],"이다."))
plot(1-spec,sens,col=2)
education = read.csv("http://datasets.flowingdata.com/education.csv")
library(lattice)
parallel(education[,2:7],horizontal.axis=FALSE,col=1)
parallel(education[,2:7],horizontal.axis=FALSE,col=1)
parallel(education[,2:7])
head(education)
library(lattice)
parallel(education[,2:7],horizontal.axis=FALSE)
parallelplot(education[,2:7],horizontal.axis=FALSE)
parallelplot(education[,2:7],horizontal.axis=FALSE,col=1)
parallel(education[,2:7],horizontal.axis=FALSE,col=1)
parallel(education[,2:7],horizontal.axis=TRUE,col=1)
parallel(education[,2:7],horizontal.axis=FALSE,col=1)
summary(education$reading)
color=education$reading>523
color
color+1
parallel(education[,2:7],horizontal.axis=FALSE,col=cikir+1)
parallelpet
(education[,2:7],horizontal.axis=FALSE,col=cikir+1)
(education[,2:7],horizontal.axis=FALSE,col=kir+1)
parallelplot(education[,2:7],horizontal.axis=FALSE,col=kir+1)
parallelplot(education[,2:7],horizontal.axis=FALSE,col=color+1)
parallel(education[,2:7],horizontal.axis=FALSE,col=color+1)
# 주성분 분석
data=read.csv(("20140528_baseball.csv"))
# 주성분 분석
data=read.csv("20140528_baseball.csv")
# 주성분 분석
data=read.csv("20140528baseball.csv")
# 주성분 분석
data=read.csv("20140528baseball.csv")
crime = read.csv("http://datasets.flowingdata.com/crimeRatesByState-formatted.csv")
setwd("/Users/ryung/Desktop/Development/R_lecture/Rdata")
# 주성분 분석
data=read.csv("20140528baseball.csv")
# 주성분 분석
data=read.csv("20140528_baseball.csv")
# 주성분 분석
data=read.csv("20140528_baseball.csv")
# 주성분 분석
data=read.csv("20140528_baseball.csv",encoding = "UTF-8")
# 주성분 분석
data=read.csv("20140528_baseball.csv",encoding = "euc-kr")
# 주성분 분석
data=read.csv("20140528_baseball.csv",encoding = "ISO-8859")
# 주성분 분석
data=read.csv("20140528_baseball.csv")
head(data)
model = prcomp(data[,2:6],scale = T)
model
summary(model)
plot(model)
model = prcomp(data[,2:6],scale = T)
data=read.csv("20140528_baseball.csv")
#setwd("D:/development/R_lecture/Rdata")
setwd("/Users/ryung/Desktop/Development/R_lecture/Rdata")
data=read.csv("20140528_baseball.csv")
head(data)
rownames(data) = data[,1]
head(data)
# 1.
stars(data[,2:6],flip.labels = F, key.loc = c(9,3), draw.segments = TRUE)
library(aplpack)
faces(data[,2:6])
# 2.
bb2013=read.csv("2013_baseball.csv")
head(bb2013)
position=bb2013$포지션
base2_pos=bb2013[,c(2,4:11)]
base2_pos2=aggregate(base2_pos[,2:9],by = list(포지션=base2_pos$포지션), FUN)
base2_pos2=aggregate(base2_pos[,2:9],by = list(포지션=base2_pos$포지션), mean)
model2 = prcomp(data[,2:6])
summary(model2)
model2
data
biplot(model)
